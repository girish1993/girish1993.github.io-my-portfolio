(this["webpackJsonpmy-portfolio"]=this["webpackJsonpmy-portfolio"]||[]).push([[0],{37:function(e,t,a){e.exports=a(52)},49:function(e,t,a){e.exports=a.p+"static/media/profile_pic.080840ce.png"},50:function(e,t,a){},52:function(e,t,a){"use strict";a.r(t);var n=a(0),i=a.n(n),r=a(18),o=a.n(r),l=a(73),s=a(22),c=a(26),m={marginLeft:"10px",padding:"10px",marginRight:"10px",fontSize:"18px"},p=function(e){var t=e.itemDetails;return i.a.createElement(c.a.Link,{style:m,href:t.link}," ",t.name," ")};var d=function(){return i.a.createElement(s.a,{bg:"dark",variant:"dark",expand:"lg"},i.a.createElement("div",{className:"flex",style:{float:"left",width:"70%"}},i.a.createElement(s.a.Brand,{style:{fontSize:"23px"},href:"#home"},"Girish Bhatta")),i.a.createElement(s.a.Toggle,{"aria-controls":"basic-navbar-nav"}),i.a.createElement(s.a.Collapse,{className:"justify-content-end",id:"basic-navbar-nav",style:{float:"right",width:"30%"}},i.a.createElement(c.a,{className:"mr-auto"},i.a.createElement(p,{itemDetails:{link:"/home",name:"Home"}}),i.a.createElement(p,{itemDetails:{link:"#link",name:"About Me"}}),i.a.createElement(p,{itemDetails:{link:"#link",name:"Projects"}}),i.a.createElement(p,{itemDetails:{link:"#link",name:"Blog"}}))))},u=a(72),g=a(69),h=a(70),f=a(75),y=a(71),v={height:"auto",maxWidth:"100%"},E=function(e){var t=e.gridContent;return"image"===t.contentType?i.a.createElement(g.a,{item:!0,xs:3},i.a.createElement(h.a,{className:t.className},i.a.createElement("img",{src:a(49),alt:t.alt,style:v}))):i.a.createElement(g.a,{item:!0,xs:9},i.a.createElement(h.a,{className:t.className},i.a.createElement(f.a,{align:"center",variant:"h6",gutterBottom:!0},t.tagline),i.a.createElement(y.a,null),i.a.createElement(y.a,null),i.a.createElement(f.a,{align:"justify",variant:"body1",gutterBottom:!0},t.desc)))},b={tagline:"A Full Stack Data Scientist with 3+ years of experience in core Back End and Front End Development intertwined with core Data Science skills of building Machine Learning models through pipelines and deploying them.",description:"I breathe and live Data. As cliched a sentence as it sounds, it is the truth. \n\n    I have always been fascinated by computers and programming in particular. This led me to take up a career path that I truly believed would suit the best for me. Being a software developer was an eventuality after all. My first job truly infused the thought in me that I was a problem solver at the core. During one of those \"usual\" assignments, I stumbled upon a data-centric problem. This problem required me to go out of my area of expertise, learn stuff on the go, and implement it. I found the whole process extremely enticing and satisfying. This exercise truly taught me the power and potency of data and how it could shape the world around us for good. That's it. There was no looking back after that.\n    \n    That small spark ignited a never-ending hunger to keep learning new techniques concepts and ways to play with data and present it in a way that could potentially bring about changes in the way business and society works. I took up a Master's degree in Data Science to further broaden my horizons. My previous work experience allows me to bring the best of both worlds - Software Development and Data Science. This helps me develop production-ready solutions that can impact the business in a positive way.\n    \n    I love applying Data-Driven Design principles and see the application providing tangible solutions to the end-user. The core of Data science surrounded and wrapped in a piece of software goes miles in providing value. My specialties and area of expertise include Data Wrangling, Statistical, and Exploratory Data Analysis, Feature Engineering, Hyperparameter optimization, Model performance measurement, and baselining, deploying the model to a production environment, Developing CI/CD pipelines to build projects and models, Developing ML pipelines.\n    \n    Some of the technologies I deal with on daily basis are: Python Django, Flask, Pandas, Numpy, Sklearn, Plotly, Matplotlib, Tensorflow, Building Neural Networks, Keras, Java Play MVC, PostgreSQL, Neo4j, Elastic search, React JS, Jquery. Some of the DevOps technologies I possess some expertise are AWS, git, Docker, Jenkins.\n    \n    I still continue exploring more on the Data science front by analyzing more complex data, working on Kaggle kernels and competitions, and upskilling myself with the latest developments in the Data Science Field."},w=Object(u.a)((function(e){return{root:{flexGrow:1,height:"80vh"},paperImage:{padding:e.spacing(.5),color:e.palette.text.secondary,backgroundColor:"#1c3052",height:"50vh",justifyContent:"center"},paperDesc:{padding:e.spacing(1),textAlign:"center",color:e.palette.text.secondary,height:"80vh"}}})),k=function(){var e=w();return i.a.createElement("div",{className:e.root,style:{marginTop:"30px"}},i.a.createElement(g.a,{container:!0,spacing:2},i.a.createElement(E,{gridContent:{contentType:"image",url:"../assets/images/profile_pic.png",className:e.paperImage,alt:"Profile Picture for the Portfolio"}}),i.a.createElement(E,{gridContent:{contentType:"text",tagline:b.tagline,desc:b.description,className:e.paperDesc}})))},D=function(){return i.a.createElement(n.Fragment,null,i.a.createElement(l.a,{m:1},i.a.createElement(d,null)),i.a.createElement(l.a,{m:1},i.a.createElement(k,null)))};a(50);var x=function(){return i.a.createElement(n.Fragment,null,i.a.createElement(D,null))};a(51);o.a.render(i.a.createElement(i.a.StrictMode,null,i.a.createElement(x,null)),document.getElementById("header"))}},[[37,1,2]]]);
//# sourceMappingURL=main.c02d43d7.chunk.js.map